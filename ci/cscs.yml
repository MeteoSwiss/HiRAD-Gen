include:
  - remote: 'https://gitlab.com/cscs-ci/recipes/-/raw/master/templates/v2/.ci-ext.yml'

stages:
  - build
  - test

variables:
  PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/hirad-gen:$CI_COMMIT_SHORT_SHA

build_job:
  stage: build
  extends: .container-builder-cscs-gh200
  variables:
    DOCKERFILE: ci/docker/Dockerfile

test_job:
  stage: test
  extends: .container-runner-clariden-gh200
  image: $PERSIST_IMAGE_NAME
  script:
    - env
    - cd /src
    #- python src/hirad/eval/run_scoring.py 
    - MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1) MASTER_PORT=29500 RANK=${SLURM_PROCID} LOCAL_RANK=${SLURM_LOCALID} WORLD_SIZE=${SLURM_NPROCS} python -c "import os, torch; import torch.distributed as dist; local_rank = int(os.environ['LOCAL_RANK']); torch.cuda.set_device(local_rank); dist.init_process_group('nccl', init_method='env://'); rank = dist.get_rank(); print(f'Hello from rank {rank}'); t = torch.tensor([rank]).to('cuda'); dist.all_reduce(t); print(f'The sum of ranks is {t}.'); dist.destroy_process_group()"
  variables:
    SLURM_JOB_NUM_NODES: 2
    SLURM_NTASKS: 4
    USE_NCCL: cuda12
    FI_CXI_DISABLE_HOST_REGISTER: 1
    FI_MR_CACHE_MONITOR: userfaultfd
    NCCL_DEBUG: INFO

